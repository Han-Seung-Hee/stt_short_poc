# Air-Gapped STT + Summarization PoC

íì‡„ë§(Air-gapped) Apple Silicon Mac í™˜ê²½ì—ì„œ ê³ ê° ìƒë‹´ ìŒì„±íŒŒì¼(.wav)ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜(STT)í•˜ê³ , í•µì‹¬ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•˜ëŠ” ì˜¤í”„ë¼ì¸ AI API ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

> [!CAUTION]
> **[í•„ë…] íì‡„ë§ í™˜ê²½ Windows OS (Server ë° 10/11) ë°°í¬ ë¶ˆê°€ ì•ˆë‚´**
> ë³¸ ì˜¤í”„ë¼ì¸ AI íŒŒì´í”„ë¼ì¸ì€ ìµœëŒ€í•œì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ìœ„í•´ Linux ë° MacOS í™˜ê²½ì„ í‘œì¤€ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ì‚¬ í™˜ê²½ì´ ë§ì´ ë¶„ë¦¬ëœ **Windows Server ê³„ì—´(2019/2022 ë“±) ë˜ëŠ” ì¼ë°˜ ë°ìŠ¤í¬í†± Windows OS(10, 11 ë“±)ì¼ ê²½ìš°, ë‹¤ìŒì˜ ì¹˜ëª…ì ì¸ ì´ìŠˆë“¤ë¡œ ì¸í•´ ì‹œìŠ¤í…œ êµ¬ì„± ë° ë°°í¬ê°€ ì›ì²œì ìœ¼ë¡œ ë¶ˆê°€í•©ë‹ˆë‹¤.**
> 
> 1. **ì˜ì¡´ì„± ë¬¸ì œ (DLL ì¶©ëŒ):** ìˆ˜ GBì— ë‹¬í•˜ëŠ” C++ ë¹Œë“œ í™˜ê²½ê³¼ AI ìˆ˜í•™ ì—°ì‚°(PyTorch, CTranslate2) ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ìœˆë„ìš° ì˜¤í”„ë¼ì¸ë§ì— ìˆ˜ë™ìœ¼ë¡œ ë°€ì–´ë„£ëŠ” ê³¼ì •ì—ì„œ ë†’ì€ í™•ë¥ ë¡œ í™˜ê²½ë³€ìˆ˜ ê¼¬ì„ ë° DLL ì¶©ëŒì´ ë°œìƒí•©ë‹ˆë‹¤.
> 2. **ì„œë²„ ì…§ë‹¤ìš´ (ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤):** í™”ì ë¶„ë¦¬(L/R)ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ì½”ì–´ì¸ FFmpegê°€ Windows ë°ëª¬(ì„œë¹„ìŠ¤) í™˜ê²½ì—ì„œëŠ” ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ë¡œ ë‚¨ì•„ ëˆ„ì ë˜ì–´ ë©”ì¸ ì„œë²„ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ì¤‘ë‹¨ì´ 100% ë°œìƒí•©ë‹ˆë‹¤.
> 3. **ì„±ëŠ¥ ë°˜í† ë§‰ (ë„ì»¤ ì˜¤ë²„í—¤ë“œ):** "ê·¸ëŸ¼ ìœˆë„ìš°ìš© Dockerì—ì„œ ëŒë¦¬ì"ê³  í•  ê²½ìš°, Windowsì˜ ê·¹í•œ ê°€ìƒí™” ì¸µ(Hyper-V ì˜¤ë²„í—¤ë“œ) ë•Œë¬¸ì— AI ì¸í¼ëŸ°ìŠ¤ ì†ë„ê°€ 70-90% ì´ìƒ ìˆ˜ì§ í•˜ë½í•©ë‹ˆë‹¤.
> 4. **GPU ì„¸íŒ… ë¬¸ì œ:** íì‡„ëœ Windowsì— NVIDIA CUDA ë“œë¼ì´ë²„ì™€ cuDNN ë°”ì´ë„ˆë¦¬ë¥¼ ì§ì ‘ ì—°ë™(ìˆ˜ë™ìœ¼ë¡œ ì—°ë™í•´ì•¼ í•¨)í•˜ë‹¤ê°€ ì»´í¬ë„ŒíŠ¸ë‚˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ê°€ ê¼¬ì—¬ ë¸”ë£¨ìŠ¤í¬ë¦°ì´ ë°œìƒí•˜ëŠ” ì¹˜ëª…ì  ìœ„í—˜ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
> 
> **ğŸ’¡ ê²°ë¡ :** ê¸€ë¡œë²Œ ì˜¤í”ˆì†ŒìŠ¤ AI ìƒíƒœê³„ì˜ í‘œì¤€ì€ Linuxì…ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„±ê³¼ ì²˜ë¦¬ ì†ë„ë¥¼ ì¡°ê¸ˆë„ ë³´ì¥í•  ìˆ˜ ì—†ëŠ” Windows(Server/PC ë“±) í™˜ê²½ì€ ì¼ì ˆ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©°, ì •ìƒì ì¸ ì‘ë™ì„ ìœ„í•´ **ë°˜ë“œì‹œ ìš´ì˜ì²´ì œê°€ Linux(Ubuntu, CentOS ë“±)ì¸ ì„œë²„ë‚˜ PCë¥¼ í• ë‹¹**ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

## ì•„í‚¤í…ì²˜

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”
                    â”‚       FastAPI Server         â”‚
                    â”‚       (port 8000)            â”‚
                    â”‚                              â”‚
  WAV Upload â”€â”€â”€â”€â”€â–¶ â”‚  POST /api/v1/process        â”‚
                    â”‚       â”‚                      â”‚
                    â”‚       â–¼                      â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚  â”‚  STT Engine  â”‚ mlx-whisperâ”‚
                    â”‚  â”‚(ìŠ¤í…Œë ˆì˜¤ ë¶„ë¦¬)â”‚ pydub        â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                    â”‚         â”‚ transcript         â”‚
                    â”‚         â–¼                    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚  â”‚  LLM Engine  â”‚ Ollama     â”‚
                    â”‚  â”‚  (3ì¤„ ìš”ì•½)    â”‚ qwen2.5:7b |
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                    â”‚         â”‚ summary            â”‚
                    â”‚         â–¼                    â”‚
                    â”‚   JSON Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–¶ { transcript, summary }
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜
```


## ê´€ë ¨ ë¬¸ì„œ
- `offline_setup_guide.md`: Mac í™˜ê²½ (íì‡„ë§) ì˜¤í”„ë¼ì¸ ì„¤ì¹˜ ê°€ì´ë“œ
- `linux_execution_guide.md`: ì¸í„°ë„·ì´ ë˜ëŠ” Linux (í…ŒìŠ¤íŠ¸/ìš´ì˜ ì„œë²„) ìŠ¤í™ ë° ì„¸íŒ… ê°€ì´ë“œ
- `linux_offline_setup_guide.md`: **[í•„ë…] ì™„ì „ íì‡„ë§(Air-Gapped) Linux ì„œë²„ ìˆ˜ë™ ì„¤ì¹˜ ê°€ì´ë“œ**
- `architecture.drawio`: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ (draw.io íŒŒì¼)

## ë¹ ë¥¸ ì‹œì‘

### ì‚¬ì „ ìš”ê±´
- Python 3.11+
- Ollama ì‹¤í–‰ ì¤‘ (`ollama serve`)
- Qwen2.5 7B ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ëª…ë ¹ì–´: `ollama run qwen2.5:7b`)

### ì„¤ì¹˜ ë° ì‹¤í–‰

**1. íŒŒì´ì¬ ê°€ìƒí™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ìµœì´ˆ 1íšŒ)
python3 -m venv .venv

# ê°€ìƒí™˜ê²½ í™œì„±í™” (í•„ìˆ˜)
source .venv/bin/activate

# ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

**2. AI Hub ë°ì´í„° í…ŒìŠ¤íŠ¸ ì¤€ë¹„ (ì˜µì…˜)**
AI Hub ë°ì´í„°ì²˜ëŸ¼ ì—¬ëŸ¬ ê°œë¡œ ìª¼ê°œì§„ ëª¨ë…¸ ì±„ë„ ë°ì´í„° íŒŒì¼ì„ ê°€ì§€ê³  ìˆë‹¤ë©´, í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•˜ë‚˜ë¡œ í•©ì³ì•¼ í•©ë‹ˆë‹¤. (ì´ ì‘ì—…ì€ PoC í…ŒìŠ¤íŠ¸ ì •í™•ë„ í‰ê°€ë¥¼ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤)
```bash
# base_data í´ë” ì•ˆì— ìˆëŠ” íŠ¹ì • í†µí™” ID ë°ì´í„° ë³‘í•© ë° ì •ë‹µì§€ ì¶”ì¶œ
python prepare_data.py MEN0005946

# ì‹¤í–‰ ì™„ë£Œ í›„ test_ready í´ë”ì— ë³‘í•©ëœ WAV íŒŒì¼ê³¼ ëŒ€ë³¸(TXT) íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.
```

**3. ë°±ê·¸ë¼ìš´ë“œ LLM ì‹¤í–‰ í™•ì¸**
*   ë¡œì»¬ Mac í™˜ê²½ì—ì„œ `Ollama` ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤. (ìƒë‹¨ ë©”ë‰´ë°” ë“±)
*   ì‚¬ìš©í•  ëª¨ë¸(`qwen2.5:7b` ë“±)ì´ ì´ë¯¸ `ollama run`ì„ í†µí•´ ë¡œë“œ ê°€ëŠ¥í•œ ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.

**4. STT + ìš”ì•½ API ì„œë²„ ì‹œì‘**
ê°€ìƒí™˜ê²½(`(.venv)`)ì´ í™œì„±í™”ëœ í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ê°€ë™í•©ë‹ˆë‹¤.
```bash
kill -9 $(lsof -t -i:8080) 2>/dev/null; .venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8080
```
*`Application startup complete.` ë¬¸êµ¬ê°€ ëœ¨ë©´ ì„œë²„ ê°€ë™ ì™„ë£Œì…ë‹ˆë‹¤.*

**5. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ì—´ê¸°**
ì„œë²„ê°€ ì¼œì§„ ìƒíƒœì—ì„œ, í„°ë¯¸ë„(ìƒˆ íƒ­) ë˜ëŠ” Finderë¥¼ í†µí•´ `index.html` íŒŒì¼ì„ ì—´ì–´ ì‹œì—°ì„ ì§„í–‰í•©ë‹ˆë‹¤.
```bash
open index.html
```

```bash
# í—¬ìŠ¤ì²´í¬
curl http://localhost:8000/api/v1/health

# STT + ìš”ì•½ í†µí•©
curl -X POST http://localhost:8000/api/v1/process \
  -F "file=@sample.wav" \
  -F "language=ko"

# STTë§Œ
curl -X POST http://localhost:8000/api/v1/transcribe \
  -F "file=@sample.wav"

# ìš”ì•½ë§Œ
curl -X POST http://localhost:8000/api/v1/summarize \
  -F "text=ìƒë‹´ ë‚´ìš© í…ìŠ¤íŠ¸..."

# ì²­í¬ ë¶„í•  í™œì„±í™” (ê¸´ ìŒì„±)
curl -X POST http://localhost:8000/api/v1/process \
  -F "file=@long_audio.wav" \
  -F "chunk_enabled=true" \
  -F "chunk_length_sec=300"
```

### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "status": "success",
  "transcript": "ê³ ê°ë‹˜ ì•ˆë…•í•˜ì„¸ìš”. ì‹ ìš©ì¹´ë“œ í•œë„ ê´€ë ¨ ë¬¸ì˜ì…ë‹ˆë‹¤...",
  "segments": [
    {"start": 0.0, "end": 3.5, "text": "ê³ ê°ë‹˜ ì•ˆë…•í•˜ì„¸ìš”."},
    {"start": 3.5, "end": 8.2, "text": "ì‹ ìš©ì¹´ë“œ í•œë„ ê´€ë ¨ ë¬¸ì˜ì…ë‹ˆë‹¤."}
  ],
  "summary": "- ê³ ê°ì´ ì‹ ìš©ì¹´ë“œ í•œë„ ì¦ì•¡ì„ ìš”ì²­í•˜ì…¨ìŠµë‹ˆë‹¤.\n- ìƒë‹´ì‚¬ê°€ ì†Œë“ì¦ë¹™ ì„œë¥˜ ì œì¶œì´ í•„ìš”í•˜ë‹¤ê³  ì•ˆë‚´í•˜ì˜€ìŠµë‹ˆë‹¤.\n- ê³ ê°ì´ 3ì¼ ë‚´ ì„œë¥˜ë¥¼ ì œì¶œí•˜ê¸°ë¡œ ì•½ì†í•˜ì…¨ìŠµë‹ˆë‹¤.",
  "model_info": {
    "stt": "mlx-whisper/small",
    "llm": "qwen2.5:7b"
  },
  "processing_time": {
    "stt_sec": 12.34,
    "llm_sec": 8.56,
    "total_sec": 20.90
  },
  "error": null
}
```

## ì„¤ì •

`config.yaml`ì—ì„œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìœ¼ë©°, í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

| í™˜ê²½ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|----------|------|--------|
| `STT_ENGINE` | STT ì—”ì§„ (`mlx` / `faster`) | `mlx` |
| `STT_MODEL_NAME` | Whisper ëª¨ë¸ í¬ê¸° | `small` |
| `STT_MODEL_PATH` | ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ | (ìë™) |
| `STT_CHUNK_ENABLED` | ì²­í¬ ë¶„í•  í™œì„±í™” | `false` |
| `LLM_MODEL_NAME` | Ollama ëª¨ë¸ëª… | `qwen2.5:7b` |
| `LLM_TIMEOUT_SEC` | LLM ì‘ë‹µ íƒ€ì„ì•„ì›ƒ(ì´ˆ) | `120` |

## ë©”ëª¨ë¦¬ ê´€ë¦¬ (16GB Unified Memory)

| ìƒíƒœ | ë©”ëª¨ë¦¬ ì‚¬ìš© |
|------|-----------|
| STT (small) ë‹¨ë… | ~1GB |
| STT (medium) ë‹¨ë… | ~1.5GB |
| LLM (7B) ë‹¨ë… | ~4.5GB |
| STT + LLM ë™ì‹œ | ~6GB |
| **16GB ì—¬ìœ ë¶„** | **~10GB** |

### ìµœì í™” íŒ
- STTì™€ LLMì€ **ìˆœì°¨ ì²˜ë¦¬**ë©ë‹ˆë‹¤ (íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ ë™ì‘)
- STT ëª¨ë¸ì€ ì²« ìš”ì²­ ì‹œ ë¡œë“œë˜ê³ , GCë¥¼ í†µí•´ í•´ì œë¥¼ ìœ ë„í•©ë‹ˆë‹¤
- OllamaëŠ” ë³„ë„ í”„ë¡œì„¸ìŠ¤ì´ë¯€ë¡œ Python ë©”ëª¨ë¦¬ì™€ ê²©ë¦¬ë©ë‹ˆë‹¤
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ `config.yaml`ì—ì„œ `stt.model_name`ì„ `base`ë¡œ ì¶•ì†Œí•˜ì„¸ìš”

## Linux ì„œë²„ í™•ì¥

í–¥í›„ GPU ì—†ëŠ” ì €ì‚¬ì–‘ Linux ì„œë²„ í˜¹ì€ NVIDIA GPUê°€ ì¥ì°©ëœ ê³ ì‚¬ì–‘ ì„œë²„ë¡œ ì´ì „ ë° ì‹¤í–‰í•˜ëŠ” êµ¬ì²´ì ì¸ ë°©ë²•ì€ **`linux_execution_guide.md`** ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

> [!WARNING]
> **íì‡„ë§(Air-Gapped) ë¦¬ëˆ…ìŠ¤ ì„œë²„ ë°°í¬ ì‹œ ì£¼ì˜ì‚¬í•­ (ë‹´ë‹¹ì í•„ë…!!)**
> í…ŒìŠ¤íŠ¸ ì„œë²„(Linux)ê°€ ì™¸ë¶€ ì¸í„°ë„·ê³¼ ì™„ì „íˆ ë‹¨ì„ ëœ íì‡„ë§ ì„œë²„ì‹¤ì— ìˆì„ ê²½ìš°, ì ˆëŒ€ "ì•Œì•„ì„œ í™˜ê²½ ì¡ìœ¼ì„¸ìš”"ë¼ê³  í•˜ì‹œë©´ ì•ˆ ë©ë‹ˆë‹¤. (`pip install` 1ì¤„ì¡°ì°¨ ë¬´ì¡°ê±´ ì—ëŸ¬ë‚©ë‹ˆë‹¤.)
> 
> ì™¸ë¶€ë§(ì¸í„°ë„·) PCì—ì„œ ë‹¤ìŒ íŒŒì¼ë“¤ì„ **USBì— ì‚¬ì „ì— ì°¨ê³¡ì°¨ê³¡ ë‹´ì•„ ë“¤ì–´ê°€ì„œ ìˆ˜ë™ ì„¤ì¹˜(A to Z)** í•´ì•¼ í•©ë‹ˆë‹¤.
> - **Python íŒ¨í‚¤ì§€ (ì‚¬ì „ ë¹Œë“œ .whl)**
> - **FFmpeg (ì •ì  ë°”ì´ë„ˆë¦¬ íƒ€ë¥´)**
> - **Ollama ì‹¤í–‰ íŒŒì¼ (ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œë³¸)**
> - **LLM ëª¨ë¸ (qwen2.5:7b í†µíŒŒì¼ ì•„ì¹´ì´ë¸Œ)**
> - **STT ëª¨ë¸ (faster-whisper CT2 ë¡œì»¬ í´ë”)**
> 
> ì¸í”„ë¼ ë‹´ë‹¹ìì™€ì˜ ì›í™œí•œ ì„¤ì¹˜ í˜‘ì—…ì„ ìœ„í•´, ìƒì„¸í•œ ë‹¤ìš´ë¡œë“œ ë°©ë²• ëª…ë ¹ì–´ ë° ìˆ˜ë™ ì„¤ì¹˜ ì»¤ë§¨ë“œë¥¼ ëª…ì‹œí•œ **`linux_offline_setup_guide.md`** ë¬¸ì„œë¥¼ ì‘ì„±í•´ ë‘ì—ˆìœ¼ë‹ˆ ì´ ë¬¸ì„œë¥¼ ì „ë‹¬í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

ê¸°ë³¸ì ìœ¼ë¡œ(ì¸í„°ë„· ì—°ê²° ì‹œ)ëŠ” ì•„ë˜ì˜ ì„¸ ê°€ì§€ ìŠ¤í…ì„ ë”°ë¦…ë‹ˆë‹¤:
1. OS í™˜ê²½ì— `ffmpeg` ì„¤ì¹˜ ë° `pip install faster-whisper`
2. `config.yaml`ì—ì„œ `stt.engine: "faster"` ë¡œ ë³€ê²½ (NVIDIA GPUê°€ ìˆë‹¤ë©´ `stt.device: "cuda"` ì¶”ê°€)
3. Ollama Linux ë²„ì „ ì„¤ì¹˜ ë° ëª¨ë¸ í’€(`ollama pull qwen2.5:7b`)

```yaml
# config.yaml (Linux)
stt:
  engine: "faster"
  model_name: "small" # GPU ì‚¬ìš© ì‹œ large-v3 ê¶Œì¥
  device: "cpu"       # GPU ì‚¬ìš© ì‹œ "cuda"ë¡œ ë³€ê²½
  model_path: "/path/to/whisper-small-ct2"
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
stt_short/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI ì§„ì…ì 
â”‚   â”œâ”€â”€ config.py             # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ pipeline.py           # STTâ†’ìš”ì•½ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”œâ”€â”€ base.py           # STT ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ mlx_engine.py     # Mac: mlx-whisper
â”‚   â”‚   â””â”€â”€ faster_engine.py  # Linux: faster-whisper
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ base.py           # LLM ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤
â”‚       â””â”€â”€ ollama_engine.py  # Ollama REST API
â”œâ”€â”€ config.yaml               # ì„¤ì • íŒŒì¼
â”œâ”€â”€ requirements.txt          # Python ì˜ì¡´ì„±
â”œâ”€â”€ offline_setup_guide.md    # ì˜¤í”„ë¼ì¸ ì„¤ì¹˜ ê°€ì´ë“œ
â”œâ”€â”€ linux_execution_guide.md  # Linux í…ŒìŠ¤íŠ¸ ì„œë²„ ì‹¤í–‰ ê°€ì´ë“œ
â””â”€â”€ README.md                 # ì´ íŒŒì¼
```
