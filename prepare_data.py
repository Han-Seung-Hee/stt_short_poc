"""AI Hub ë¹„ì‹ë³„í™” í†µí™” í…Œì´í„° ë³‘í•© íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸.

AI Hubì˜ ì½œì„¼í„°/ì •ì‹ ê±´ê°• ìƒë‹´ ë°ì´í„°ëŠ” ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì§§ê²Œ ìª¼ê°œì ¸ ìˆìŠµë‹ˆë‹¤.
ë³¸ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìª¼ê°œì§„ ì—¬ëŸ¬ ê°œì˜ `.wav` íŒŒì¼ê³¼ `.json` ë¼ë²¨ë§ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ì´ì–´ ë¶™ì—¬ì„œ,
STT PoC í…ŒìŠ¤íŠ¸ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” 1ê°œì˜ í†µí•© ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ í‰ê°€ ë¹„êµìš© ì •ë‹µì§€(ëŒ€ë³¸) ë¬¸ì„œë¡œ ìƒì„±í•´ ì¤ë‹ˆë‹¤.

[ì‚¬ìš© ë°©ë²•]
1. ê°€ìƒí™˜ê²½ í™œì„±í™”ê°€ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (`source .venv/bin/activate`)
2. í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ë³€í™˜í•˜ê³  ì‹¶ì€ ëŒ€í™” í´ë”ì˜ 'ê³ ìœ  ID'ë¥¼ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.

   ê¸°ë³¸ ëª…ë ¹ì–´ ì˜ˆì‹œ:
   $ python prepare_data.py MEN0005946

[ì„ íƒ ì˜µì…˜ (Optional)]
--base : AI Hub ì›ë³¸ ë°ì´í„°('wav', 'labeling' í´ë”ê°€ ìˆëŠ”) ìµœìƒìœ„ ê²½ë¡œ (ê¸°ë³¸ê°’: 'base_data')
--out  : ì¶”ì¶œ ë° ë³‘í•©ëœ íŒŒì¼ì´ ì €ì¥ë  ì¶œë ¥ í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: 'test_ready')

   ì˜µì…˜ ì ìš© ëª…ë ¹ì–´ ì˜ˆì‹œ:
   $ python prepare_data.py MEN0005946 --base ./my_data_folder --out ./result_folder

[ì¶œë ¥ ê²°ê³¼ë¬¼]
ì‹¤í–‰ì´ ì™„ë£Œë˜ë©´ `--out` ìœ¼ë¡œ ì§€ì •í•œ í´ë”(`test_ready/`) ê²½ë¡œì— 2ê°œì˜ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.
1. [ID]_merged.wav : index.html ë“± STT ì„œë¹„ìŠ¤ì— ì—…ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ë³‘í•©ëœ 1ê°œì˜ í†µí™” ì˜¤ë””ì˜¤ íŒŒì¼
2. [ID]_ground_truth.txt : í™”ì(ìƒë‹´ì‚¬/ê³ ê°) êµ¬ë¶„ê³¼ í•¨ê»˜ ì‹œê°„ ìˆœì„œë¡œ ì •ë¦¬ëœ ì‹¤ì œ ëŒ€í™” ë‚´ì—­ (ì„±ëŠ¥ ë¹„êµ/í‰ê°€ìš© ë¬¸ì„œ)
"""

import argparse
import json
import logging
from pathlib import Path

from pydub import AudioSegment

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")


def merge_aihub_data(base_dir: str, conversation_id: str, output_dir: str):
    base_path = Path(base_dir)
    wav_base = base_path / "wav"
    label_base = base_path / "labeling"
    
    # í•´ë‹¹ IDë¥¼ ê°€ì§„ ë””ë ‰í† ë¦¬ ì°¾ê¸° (í•˜ìœ„ í´ë” ê¹Šì´ì— ìƒê´€ì—†ì´ íƒìƒ‰)
    wav_dirs = list(wav_base.rglob(conversation_id))
    label_dirs = list(label_base.rglob(conversation_id))
    
    if not wav_dirs:
        logging.error(f"WAV ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wav_base} í•˜ìœ„ì— {conversation_id} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not label_dirs:
        logging.warning(f"ë¼ë²¨ë§ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {label_base} í•˜ìœ„ì— {conversation_id} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ ë³‘í•©(ìŠ¤í…Œë ˆì˜¤)ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
        label_dir = None
    else:
        label_dir = label_dirs[0]
        
    wav_dir = wav_dirs[0]
    
    # íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ ë° ì •ë ¬ (íŒŒì¼ ì´ë¦„ì˜ ìˆœë²ˆì´ ì •ë ¬ ê¸°ì¤€ì´ ë©ë‹ˆë‹¤)
    wav_files = sorted(list(wav_dir.glob("*.wav")))
    json_files = sorted(list(label_dir.glob("*.json"))) if label_dir else []
    
    if not wav_files:
        logging.error(f"[{wav_dir}] ê²½ë¡œì— WAV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
        
    logging.info(f"==== íŒŒì‹± ì‹œì‘: {conversation_id} ====")
    logging.info(f"WAV íŒŒì¼ {len(wav_files)}ê°œ, JSON íŒŒì¼ {len(json_files)}ê°œ ë¡œë“œ ì™„ë£Œ")
    
    merged_audio = AudioSegment.empty()
    ground_truth_lines = []
    
    # JSON íŒŒì¼ë“¤ì„ íŒŒì¼ ì´ë¦„(í™•ì¥ì ì œì™¸) ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘
    json_dict = {f.stem: f for f in json_files}
    
    for w_file in wav_files:
        stem = w_file.stem
        
        # Audio ë³‘í•© (íŒŒì¼ëª…ì˜ í™”ì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢Œ/ìš° ìŠ¤í…Œë ˆì˜¤ ë¶„ë¦¬ ì ìš©)
        audio_segment = AudioSegment.from_wav(str(w_file))
        
        # íŒŒì¼ëª…ì„ '_'ë¡œ ë¶„ë¦¬í•˜ì—¬ 'A' ë˜ëŠ” 'B' ì‹ë³„ (ì˜ˆ: HOS0004195_A_001.wav)
        parts = stem.split("_")
        if "A" in parts:
            panned_segment = audio_segment.pan(-1.0) # A(ìƒë‹´ì›): ì™¼ìª½ ìŠ¤í”¼ì»¤
        elif "B" in parts:
            panned_segment = audio_segment.pan(1.0)  # B(ê³ ê°): ì˜¤ë¥¸ìª½ ìŠ¤í”¼ì»¤
        else:
            panned_segment = audio_segment.pan(0.0)  # ì‹ë³„ ë¶ˆê°€ ì‹œ ì¤‘ì•™
            
        merged_audio += panned_segment
        
        # ëŒ€ì‘ë˜ëŠ” JSONì—ì„œ í…ìŠ¤íŠ¸(ì •ë‹µ)ì™€ í™”ì ì •ë³´ ì¶”ì¶œ
        j_file = json_dict.get(stem)
        if j_file and j_file.exists():
            with open(j_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                info = data.get("info", [{}])[0].get("metadata", {})
                speaker_type = info.get("speaker_type", "ì•Œìˆ˜ì—†ìŒ") # ê³ ê° or ìƒë‹´ì‚¬
                
                texts = data.get("inputText", [])
                text_content = " ".join([t.get("orgtext", "") for t in texts])
                
                ground_truth_lines.append(f"[{speaker_type}] {text_content}")
        else:
            ground_truth_lines.append(f"[ì•Œìˆ˜ì—†ìŒ] ({stem} ë¼ë²¨ë§ ë§¤ì¹­ ì‹¤íŒ¨)")
            
    # ê²°ê³¼ë¬¼ ì €ì¥ìš© í´ë” ìƒì„±
    out_path = Path(output_dir)
    out_path.mkdir(parents=True, exist_ok=True)
    
    out_wav = out_path / f"{conversation_id}_merged.wav"
    out_txt = out_path / f"{conversation_id}_ground_truth.txt"
    
    # ì˜¤ë””ì˜¤ ë‚´ë³´ë‚´ê¸° (ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
    logging.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë³‘í•© ë° ì €ì¥ ì¤‘... (ì´ {len(merged_audio)/1000:.1f}ì´ˆ ë¶„ëŸ‰)")
    merged_audio.export(out_wav, format="wav")
    
    # í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°
    with open(out_txt, "w", encoding="utf-8") as f:
        f.write("\n".join(ground_truth_lines))
        
    logging.info(f"==== ì²˜ë¦¬ ì™„ë£Œ! ====")
    logging.info(f" ğŸ§ ì—…ë¡œë“œìš© í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤: {out_wav}")
    logging.info(f" ğŸ“„ ì›ë³¸ ë¹„êµìš© ëŒ€ë³¸(ì •ë‹µì§€): {out_txt}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="AI Hub ë¶„í•  ë°ì´í„° ë³‘í•©ê¸° (PoC í…ŒìŠ¤íŠ¸ìš©)")
    parser.add_argument("call_id", help="í•©ì¹˜ê³  ì‹¶ì€ ëŒ€í™” ID (ì˜ˆ: MEN0005946)")
    parser.add_argument("--base", default="base_data", help="base_data ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ìœ„ì¹˜")
    parser.add_argument("--out", default="test_ready", help="ì™„ì„±ëœ íŒŒì¼ì´ ì €ì¥ë  ìœ„ì¹˜")
    args = parser.parse_args()
    
    merge_aihub_data(args.base, args.call_id, args.out)
